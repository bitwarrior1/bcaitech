# 최적화 관련 용어들

### Important Concepts in Optimization

* Generalization   
  Generalization Gap을 training 데이터에 대한 정확성과 test 데이터에 대한 정확성 사이의 차이를 말한다.  
  이 Gap이 작으면 Generalization이 좋다고 말한다.

* UnderFitting vs OverFitting   
  오버피팅은 학습데이터에 대해 잘 에측하지만 테스트 데이터에 대해서는 잘 에측하지 않는 것을 말한다.  
  언더피팅은 네트워크가 너무 간단하거나 학습이 부족한 것을 말한다.  
  
* Cross validation   

  학습 / 테스트 데이터를 나누는 기법 중 하나이다.  
  데이터를 일정한 간격으로 나누고 (k개의 fold) 그 중 하나를 validation data로 정한다.  
  validation data를 뺀 나머지 학습 데이터를 이용해서 학습하고 validation data를 이용해서 잘 학습되었는지 판단한다.  
  이 과정을 validation data을 돌아가면서 다른 fold로 지정하고 나머지로 학습하고 validation data로 정확성 판단을 반복한다.    
  
  Hyper Parameter를 찾는 경우에 쓰이고 있다. ※하이퍼 파라미터(= learning rate, network크기, loss function...)  
  Cross validation기법을 이용해서 적절한 하이퍼 파라미터를 찾은 후  
  전체 학습 데이터를 이용해서 학습을 시킨다.
  
* Bias and Variance
  * Bias
  정확한 값을 예측하지 못한다. (High Bias)
  * Variance
  유사한 데이터에 대해 예측값이 일정하지 못하다. (High Bias)
  
  서로간에 trade off가 적용될 수 있다.  
  cost를 minimize 한다는 것은  세가지 부분, bias, variance, noise로 나뉠 수 있다.
  
* bootstrapping  
  Bootstrapping is any test or metric that uses random sampling with replacement  
  전체데이터가 아니라 일부데이터를 이용하는 방법  
  그 중에서 ...  
  * Bagging (Bootstrapping aggregation)
    * 부트스트래핑으로 여러개의 모델을 학습시킨 후   
    여러 모델에서 나온 결과를 합계(voting or averaging)하는 방법
    
    * 앙상블(ensemble)이라고 불리고도 한다. 일반적으로 한가지 모델보다 좋은 결과과 나와서 캐글 등에서 많이 사용
  
  * Boosting
    * 일부의 데이터에서만 잘 동작하는 모델들(weak learner)을 만들고 그 모델들을 sequential하게 연결시키는 방법
    
---  

### Practical Gradient Descent Methods

* 그래디언트 3세지 분류
  * SGD : single data
  * Mini-batch : subset of data
  * Batch : whole data

* 배치사이즈는 많이 중요하다.
  * 큰 배치사이즈 -> sharp한 미니멈 위치에 도달한다
  * 작은 배치사이즈 -> flat한 미니멈 위치에 도달한다
  
  학습 function 상에서 flat한 미니멈 위치일 때,  
  테스트 function 과의 차이가 적을 것이므로  
  적은 배치사이즈를 사용하는 것이 더 좋다.  
  (반대로, sharp한 지점 주위에서는 데이터의 작은 차이에도 학습function과 테스트function의 차이가 클 수 있다)
  
  큰 배치사이즈의 활용은 논문참고?
  
* Gradient Descent Methods  
  
  * SGD
  
  * Momentum  
  이전 Gradient 방향을 기억해서 다음 그래디언트에 영향을 주는 방법.  
  Gradient 계산시 이전 Gradient에 하이퍼파라미터를 곱해준 값을 더해준다. (accumulation)  
  모멘텀은 최저점으로 빠르게 이동하지만, 부호가 바뀌어도 이전 방향으로 가기 때문에 최저점으로 수렴하지 못할 수 있다.
  
  * Nesterov accelerated gradient
  Momentum 방법과 유사한데 gradient 대신 Lookahead gradient을 계산 후 모멘텀을 더해준다.  
  Lookahead gradient은 이동할 방향으로 미리 이동해서 gradient를 계산하는 방법이다.
  
  * Adagrad
  네트워크의 각각의 파라미터에 대해 현재까지의 변화에 따라서 gradient의 양을 달리 계산한다.  
  많이 변한 파라미터들은 변화량을 줄이고, 조금 변한 파라미터들은 변화량을 늘리는 방법이다.
  
  학습을 오래하면 변화량이 줄어들어 문제가 된다.
  
  * Adadelta  
  Adagrad가 가진 단점을 해결한다.  
  윈도우 사이즈(일정 학습기간)만큼 동안만의 각 파라미터의 변화량을 본다.
  learning rate가 없다!
  
  Exponential Moving Average(EMA).

  * RMSprop  
    
  * Adam  
  Adaptive Moment Estimation.    
  
  EMA of gradient squres를 사용해서 adaptive하게 learning rate를 바꾸는 것과  
  이전 gradient의 정보를 사용하는 momentum을  
  합쳐서 사용하는 방법  
  
--- 

### Regularization
  
  
  

  















 


  
  
