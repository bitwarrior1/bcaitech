## 베이즈 정리  

베이즈 정리는 데이터가 새로 추가되었을 때 정보를 업데이트하는 방식에 대한 기반이 되므로  
오늘날 머신러닝에 사용되는 예측모형의 방법론으로 굉장히 많이 사용되는 개념입니다. 

### 용어
<img src="https://github.com/bitwarrior1/bcaitech/blob/main/new/img/bayesian.png" width="800" height="300" />

* likehood  
현재 모수에서 이 데이터가 관찰된 확률

* D  
데이터

* 사전확률  
모델에서 계산하고 싶은 파라미터, 모수  
데이터 분석 전에 주어진다.(=가정한다)

* 사후확률  
데이터가 주어져 있을 때 이 파라미터가 성립된 확률,  
데이터를 관찰한 후에 정해진다.

이전 사후확률이 사전확률이 되며 사후확률을 갱신한다

### 조건부확률과 인과관계
* 조건부 확률로 인과관계를 추론 할 수 없다.

* 인과관계는 데이터 분포의 변화에 강건한 예측모델을 만들 때 필요하다.

* 조건부확률 기반은  데이터 분포가 변하면 모델이 예측정확도가 망가질 수 있다.

* 인과관계를 알아내기 위해서는 중첩요인의 효과를 제거해야한다.
  * 중첩요인
  예시) 키와 지능의 관계라면 나이 중첩효과를 제거해야한다.


### Q) 베이즈 정리가 딥러닝에서 어느 부분과 관련이 있지?

* 나이브 베이지안 분류자 ??

* Bayesian Deep Learning ?? https://taeoh-kim.github.io/blog/bayesian1/

### Further Question 
Regression Task, Classification Task, Probabilistic Task의 Loss 함수(or 클래스)는 Pytorch에서 어떻게 구현이 되어있을까요?  

Module 클래스에 \_\_call\_\_ 이 구현되어있어서 클래스를 함수처럼 사용한다.

