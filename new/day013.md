## 강의

* Convolution 과 pooling layers 는 feature extraction의 의미를 갖는다

* 반면 fully connected layer 은 decision making(e.g., classification)의 의미를 갖는다

* fully connected layer는 최소화 시키는 추세이다.  (파라미터의 숫자에 달려있지만 일반적으로 그렇다)  

* 학습하고자 하는 모델의 파라미터 숫자가 늘어날수록 학습이 어렵고 generalization performance이 떨어진다. 
  = 학습에서 얻은 결과가 실제 테스트에서의 결과와 차이가 많이 난다는 것을 의미한다.

* 그래서 컨볼루션 레이어를 deep하게 하지만 파라미터 숫자를 줄어는 방식을 이용한다.  
  
* 일반적으로 어떤 NN에서 layer별로 몇개의 파라미터, 전체에 파라미터에 대한 감을 가지고 있어야 한다.

## Convolution

* 커널의 채널 크기는 입력의 채널 크기와 같다.

* 커널의 개수에 따라 출력의 채널 크기가 결정된다.
  커널이 10개라면 출력의 채널 크기가 10이 된다.

* dense layer, MLP layer의 파라미터 숫자가 일반적으로 컨볼루션보다 훨씬크다.  
  컨볼루션의 경우 커널이 입력의 모든 영역에 동일하게 적용되기 때문에 파라미터 수가 상대적으로 적다.   
  그래서 위에서 말했듯이 fully connected layer부분의 파라미터 수를 줄이고   
  컨볼루션 레이어를 깊게 쌓는 시도를 많이 한다.  

* 그러기 위한 시도 중 하나가 1X1 Convolution 이다. 
  깊이를 증가시키며 파라미터숫자를 줄인다. (= Dimension reduction)
  예) bottleneck 아키텍처

